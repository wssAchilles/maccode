"""
æ•°æ®é¢„å¤„ç†æ¨¡å— - å®¶åº­å¾®ç½‘èƒ½æºä¼˜åŒ–ç³»ç»Ÿ
Data Preprocessing Module for Home Microgrid Energy Optimization System

ä½œè€…: èµ„æ·±æ•°æ®å·¥ç¨‹å¸ˆ
åŠŸèƒ½: å®Œæ•´çš„ ETL æµç¨‹ï¼ŒåŒ…æ‹¬æ•°æ®è¯»å–ã€ç‰¹å¾èšåˆã€åˆå¹¶ã€é‡é‡‡æ ·å’Œç‰¹å¾å·¥ç¨‹
"""

import pandas as pd
import numpy as np
from pathlib import Path
from typing import Tuple, List
import warnings

warnings.filterwarnings('ignore')

# ç¡®ä¿èƒ½å¯¼å…¥ config (å¦‚æœç›´æ¥è¿è¡Œè„šæœ¬)
import sys
if str(Path(__file__).parent.parent) not in sys.path:
    sys.path.insert(0, str(Path(__file__).parent.parent))

from config import Config


class EnergyDataProcessor:
    """
    èƒ½æºæ•°æ®å¤„ç†å™¨ç±»
    è´Ÿè´£å¤„ç†åˆ†é’Ÿçº§èƒ½è€—æ•°æ®ï¼Œè½¬æ¢ä¸ºå°æ—¶çº§è®­ç»ƒæ•°æ®
    """
    
    def __init__(self, raw_data_dir: str = None, output_dir: str = None):
        """
        åˆå§‹åŒ–æ•°æ®å¤„ç†å™¨
        
        Args:
            raw_data_dir: åŸå§‹æ•°æ®ç›®å½•è·¯å¾„
            output_dir: è¾“å‡ºæ•°æ®ç›®å½•è·¯å¾„
        """
        # è·å–é¡¹ç›®æ ¹ç›®å½•ï¼ˆback/services çš„ä¸Šä¸¤çº§ï¼‰
        self.script_dir = Path(__file__).parent
        self.project_root = self.script_dir.parent.parent
        
        # è®¾ç½®æ•°æ®è·¯å¾„
        self.raw_data_dir = Path(raw_data_dir) if raw_data_dir else self.project_root / 'data' / 'raw'
        self.output_dir = Path(output_dir) if output_dir else self.project_root / 'data' / 'processed'
        
        # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
        self.output_dir.mkdir(parents=True, exist_ok=True)
        
        print(f"ğŸ“ åŸå§‹æ•°æ®ç›®å½•: {self.raw_data_dir}")
        print(f"ğŸ“ è¾“å‡ºæ•°æ®ç›®å½•: {self.output_dir}")
    
    def read_csv_with_date(self, file_path: Path) -> pd.DataFrame:
        """
        è¯»å– CSV æ–‡ä»¶å¹¶è§£ææ—¥æœŸåˆ—
        
        Args:
            file_path: CSV æ–‡ä»¶è·¯å¾„
            
        Returns:
            è§£æåçš„ DataFrame
        """
        print(f"ğŸ“– æ­£åœ¨è¯»å–: {file_path.name}")
        df = pd.read_csv(file_path, parse_dates=['Date'])
        print(f"   âœ“ è¯»å–å®Œæˆï¼Œå…± {len(df)} è¡Œæ•°æ®")
        return df
    
    def aggregate_power_columns(self, df: pd.DataFrame, floor_name: str) -> pd.DataFrame:
        """
        èšåˆæ‰€æœ‰åŠŸç‡åˆ—ï¼ˆåŒ…å« 'kW' çš„åˆ—ï¼‰
        
        Args:
            df: è¾“å…¥ DataFrame
            floor_name: æ¥¼å±‚åç§°ï¼ˆç”¨äºç”Ÿæˆåˆ—åï¼‰
            
        Returns:
            æ·»åŠ äº†æ€»è´Ÿè½½åˆ—çš„ DataFrame
        """
        # è‡ªåŠ¨è¯†åˆ«æ‰€æœ‰åŒ…å« 'kW' çš„åˆ—
        power_columns = [col for col in df.columns if 'kW' in col]
        
        if not power_columns:
            raise ValueError(f"åœ¨ {floor_name} æ•°æ®ä¸­æœªæ‰¾åˆ°åŒ…å« 'kW' çš„åŠŸç‡åˆ—")
        
        print(f"ğŸ”Œ {floor_name} å‘ç° {len(power_columns)} ä¸ªåŠŸç‡åˆ—")
        
        # è®¡ç®—æ€»è´Ÿè½½
        total_load_col = f'Total_Load_{floor_name}'
        df[total_load_col] = df[power_columns].sum(axis=1)
        
        print(f"   âœ“ å·²ç”Ÿæˆ {total_load_col}ï¼ŒèŒƒå›´: {df[total_load_col].min():.2f} - {df[total_load_col].max():.2f} kW")
        
        return df
    
    def extract_temperature(self, df: pd.DataFrame) -> pd.DataFrame:
        """
        æå–æ¸©åº¦åˆ—ï¼ˆåŒ…å« 'degC' çš„åˆ—ï¼‰
        
        Args:
            df: è¾“å…¥ DataFrame
            
        Returns:
            æ·»åŠ äº†æ¸©åº¦åˆ—çš„ DataFrame
        """
        # è‡ªåŠ¨è¯†åˆ«æ‰€æœ‰åŒ…å« 'degC' çš„åˆ—
        temp_columns = [col for col in df.columns if 'degC' in col]
        
        if not temp_columns:
            raise ValueError("æœªæ‰¾åˆ°åŒ…å« 'degC' çš„æ¸©åº¦åˆ—")
        
        print(f"ğŸŒ¡ï¸  å‘ç° {len(temp_columns)} ä¸ªæ¸©åº¦åˆ—")
        
        # å¦‚æœæœ‰å¤šä¸ªæ¸©åº¦åˆ—ï¼Œå–å¹³å‡å€¼
        if len(temp_columns) > 1:
            df['Temperature'] = df[temp_columns].mean(axis=1)
            print(f"   âœ“ å·²å¯¹å¤šä¸ªæ¸©åº¦åˆ—å–å¹³å‡å€¼ç”Ÿæˆ Temperature")
        else:
            df['Temperature'] = df[temp_columns[0]]
            print(f"   âœ“ å·²æå–æ¸©åº¦åˆ—: {temp_columns[0]} -> Temperature")
        
        return df
    
    def merge_floors(self, df1: pd.DataFrame, df2: pd.DataFrame) -> pd.DataFrame:
        """
        åˆå¹¶ä¸¤ä¸ªæ¥¼å±‚çš„æ•°æ®
        
        Args:
            df1: Floor1 æ•°æ®
            df2: Floor2 æ•°æ®
            
        Returns:
            åˆå¹¶åçš„ DataFrame
        """
        print("ğŸ”— æ­£åœ¨åˆå¹¶ä¸¤ä¸ªæ¥¼å±‚çš„æ•°æ®...")
        
        # é€‰æ‹©éœ€è¦çš„åˆ—è¿›è¡Œåˆå¹¶
        df1_subset = df1[['Date', 'Total_Load_F1']].copy()
        df2_subset = df2[['Date', 'Total_Load_F2', 'Temperature']].copy()
        
        # å†…è¿æ¥
        merged_df = pd.merge(df1_subset, df2_subset, on='Date', how='inner')
        
        print(f"   âœ“ åˆå¹¶å®Œæˆï¼Œå…± {len(merged_df)} è¡Œæ•°æ®")
        
        # è®¡ç®—å…¨å±‹æ€»è´Ÿè½½
        merged_df['Site_Load'] = merged_df['Total_Load_F1'] + merged_df['Total_Load_F2']
        
        print(f"   âœ“ å·²è®¡ç®— Site_Loadï¼ŒèŒƒå›´: {merged_df['Site_Load'].min():.2f} - {merged_df['Site_Load'].max():.2f} kW")
        
        return merged_df
    
    def resample_to_hourly(self, df: pd.DataFrame) -> pd.DataFrame:
        """
        å°†åˆ†é’Ÿçº§æ•°æ®é‡é‡‡æ ·ä¸ºå°æ—¶çº§æ•°æ®
        
        Args:
            df: è¾“å…¥ DataFrame
            
        Returns:
            é‡é‡‡æ ·åçš„ DataFrame
        """
        print("â° æ­£åœ¨é‡é‡‡æ ·ä¸ºå°æ—¶çº§æ•°æ®...")
        
        # è®¾ç½® Date ä¸ºç´¢å¼•
        df = df.set_index('Date')
        
        # æŒ‰å°æ—¶é‡é‡‡æ ·ï¼Œå¯¹æ‰€æœ‰æ•°å€¼åˆ—æ±‚å¹³å‡å€¼
        hourly_df = df.resample('1H').mean()
        
        # å‰å‘å¡«å…… NaN å€¼
        hourly_df = hourly_df.ffill()
        
        # é‡ç½®ç´¢å¼•
        hourly_df = hourly_df.reset_index()
        
        print(f"   âœ“ é‡é‡‡æ ·å®Œæˆï¼Œä» {len(df)} è¡Œå‹ç¼©åˆ° {len(hourly_df)} è¡Œ")
        print(f"   âœ“ å·²ä½¿ç”¨å‰å‘å¡«å……å¤„ç† NaN å€¼")
        
        return hourly_df
    
    def add_price_feature(self, df: pd.DataFrame) -> pd.DataFrame:
        """
        æ·»åŠ ç”µä»·ç‰¹å¾ï¼ˆæ¨¡æ‹Ÿå³°è°·ç”µä»·ï¼‰
        
        Args:
            df: è¾“å…¥ DataFrame
            
        Returns:
            æ·»åŠ äº†ç”µä»·åˆ—çš„ DataFrame
        """
        print("ğŸ’° æ­£åœ¨æ·»åŠ ç”µä»·ç‰¹å¾...")
        
        def get_price(hour: int) -> float:
            """æ ¹æ®å°æ—¶è¿”å›ç”µä»· (ä»é…ç½®è¯»å–)"""
            schedule = Config.PRICE_SCHEDULE
            
            if hour in schedule['peak_hours_list']:
                return schedule['peak']
            elif hour in schedule['normal_hours_list']:
                return schedule['normal']
            else:
                return schedule['valley']
        
        # æå–å°æ—¶å¹¶æ˜ å°„ç”µä»·
        df['Hour'] = df['Date'].dt.hour
        df['Price'] = df['Hour'].apply(get_price)
        
        schedule = Config.PRICE_SCHEDULE
        print(f"   âœ“ å·²æ·»åŠ  Price åˆ—")
        print(f"   - è°·æ—¶ ({schedule['valley_desc']}): {schedule['valley']} {schedule['currency']}")
        print(f"   - å¹³æ—¶ ({schedule['normal_desc']}): {schedule['normal']} {schedule['currency']}")
        print(f"   - å³°æ—¶ ({schedule['peak_desc']}): {schedule['peak']} {schedule['currency']}")
        
        return df
    
    def add_time_features(self, df: pd.DataFrame) -> pd.DataFrame:
        """
        æ·»åŠ æ—¶é—´ç‰¹å¾
        
        Args:
            df: è¾“å…¥ DataFrame
            
        Returns:
            æ·»åŠ äº†æ—¶é—´ç‰¹å¾çš„ DataFrame
        """
        print("ğŸ“… æ­£åœ¨æ·»åŠ æ—¶é—´ç‰¹å¾...")
        
        # Hour å·²åœ¨ add_price_feature ä¸­æ·»åŠ 
        if 'Hour' not in df.columns:
            df['Hour'] = df['Date'].dt.hour
        
        # æ·»åŠ æ˜ŸæœŸå‡  (0=Monday, 6=Sunday)
        df['DayOfWeek'] = df['Date'].dt.dayofweek
        
        print(f"   âœ“ å·²æ·»åŠ  Hour (0-23) å’Œ DayOfWeek (0-6) ç‰¹å¾")
        
        return df

    def add_advanced_features(self, df: pd.DataFrame, dropna: bool = True) -> pd.DataFrame:
        """
        æ·»åŠ é«˜çº§ç‰¹å¾ (Lag, Rolling, Interaction)
        å®ç°è®ºæ–‡ç¬¬3ç« æè¿°çš„ç‰¹å¾å·¥ç¨‹
        
        Args:
            df: è¾“å…¥ DataFrame
            dropna: æ˜¯å¦åˆ é™¤å› ç‰¹å¾æ„å»ºäº§ç”Ÿçš„ NaN è¡Œ (é»˜è®¤ True)
        """
        print("ğŸš€ æ­£åœ¨æ·»åŠ é«˜çº§ç‰¹å¾ (Lag, Rolling, Interaction)...")
        
        # ç¡®ä¿æ•°æ®æŒ‰æ—¶é—´æ’åº
        df = df.sort_values('Date').reset_index(drop=True)
        
        # 1. æ»åç‰¹å¾ (Lag Features)
        # Lag 1h: ä¸Šä¸€å°æ—¶è´Ÿè½½
        df['Lag_1h'] = df['Site_Load'].shift(1)
        # Lag 24h: æ˜¨æ—¥æ­¤æ—¶
        df['Lag_24h'] = df['Site_Load'].shift(24)
        # Lag 168h: ä¸Šå‘¨æ­¤æ—¶
        df['Lag_168h'] = df['Site_Load'].shift(168)
        
        # 2. æ»‘åŠ¨çª—å£ç‰¹å¾ (Rolling Window Statistics)
        # å¿…é¡»å…ˆ shift(1) é¿å…æœªæ¥ä¿¡æ¯æ³„éœ² (Data Leakage)
        # ä½¿ç”¨ shift(1) åï¼Œrolling å–çš„æ˜¯ t-1, t-2... çš„æ•°æ®
        
        # è¿‡å»6å°æ—¶å‡å€¼
        df['Rolling_Mean_6h'] = df['Site_Load'].shift(1).rolling(window=6).mean()
        # è¿‡å»6å°æ—¶æ ‡å‡†å·®
        df['Rolling_Std_6h'] = df['Site_Load'].shift(1).rolling(window=6).std()
        # è¿‡å»24å°æ—¶å‡å€¼
        df['Rolling_Mean_24h'] = df['Site_Load'].shift(1).rolling(window=24).mean()
        
        # 3. äº¤äº’ç‰¹å¾ (Interaction Features)
        # Temperature x Hour: æ•æ‰ä¸åŒæ—¶æ®µæ¸©åº¦çš„å½±å“å·®å¼‚ (å¦‚ä¸­åˆé«˜æ¸©vsæ·±å¤œé«˜æ¸©)
        df['Temp_x_Hour'] = df['Temperature'] * df['Hour']
        
        # Lag_24h x DayOfWeek: æ•æ‰å†å²è´Ÿè½½åœ¨ä¸åŒæ˜ŸæœŸçš„æƒ¯æ€§å·®å¼‚
        df['Lag24_x_DayOfWeek'] = df['Lag_24h'] * df['DayOfWeek']
        
        # 4. æ¸…æ´— NaN (ç”±äº shift/rolling äº§ç”Ÿçš„å¤´éƒ¨ç¼ºå¤±)
        original_len = len(df)
        
        if dropna:
            df = df.dropna().reset_index(drop=True)
            dropped_len = original_len - len(df)
            print(f"   âœ“ å·²æ·»åŠ  Lag: 1h, 24h, 168h")
            print(f"   âœ“ å·²æ·»åŠ  Rolling: Mean(6h, 24h), Std(6h)")
            print(f"   âœ“ å·²æ·»åŠ  Interaction: Temp*Hour, Lag24*DoW")
            print(f"   âš ï¸  å› ç‰¹å¾æ„å»ºå‰”é™¤äº†å‰ {dropped_len} è¡Œæ•°æ® (Warm-up Period)")
        else:
            print(f"   âœ“ å·²æ·»åŠ é«˜çº§ç‰¹å¾ (ä¿ç•™ NaN è¡Œï¼Œå…± {original_len} è¡Œ)")
        
        return df
    
    def save_processed_data(self, df: pd.DataFrame, filename: str = 'cleaned_energy_data.csv') -> Path:
        """
        ä¿å­˜å¤„ç†åçš„æ•°æ®
        
        Args:
            df: å¤„ç†åçš„ DataFrame
            filename: è¾“å‡ºæ–‡ä»¶å
            
        Returns:
            è¾“å‡ºæ–‡ä»¶è·¯å¾„
        """
        output_path = self.output_dir / filename
        
        print(f"ğŸ’¾ æ­£åœ¨ä¿å­˜å¤„ç†åçš„æ•°æ®åˆ°: {output_path}")
        df.to_csv(output_path, index=False)
        print(f"   âœ“ ä¿å­˜æˆåŠŸï¼")
        
        return output_path
    
    def print_summary(self, df: pd.DataFrame):
        """
        æ‰“å°æ•°æ®æ‘˜è¦
        
        Args:
            df: DataFrame
        """
        print("\n" + "="*80)
        print("ğŸ“Š æ•°æ®å¤„ç†å®Œæˆï¼ä»¥ä¸‹æ˜¯å¤„ç†åçš„æ•°æ®æ‘˜è¦ï¼š")
        print("="*80)
        
        print(f"\nğŸ“ˆ æ•°æ®å½¢çŠ¶: {df.shape[0]} è¡Œ Ã— {df.shape[1]} åˆ—")
        
        print(f"\nğŸ“‹ å‰ 5 è¡Œæ•°æ®:")
        print(df.head().to_string())
        
        print(f"\nğŸ“Š æ•°æ®ç»Ÿè®¡ä¿¡æ¯:")
        print(df.describe().to_string())
        
        print(f"\nğŸ” åˆ—ååˆ—è¡¨:")
        for i, col in enumerate(df.columns, 1):
            print(f"   {i}. {col}")
        
        print(f"\nâœ… æ€»è¡Œæ•°: {len(df)}")
        print("="*80 + "\n")


def preprocess_energy_data(
    raw_data_dir: str = None,
    output_dir: str = None,
    year: str = None,
    floors: List[int] = None,
    output_file: str = None
) -> pd.DataFrame:
    """
    å®Œæ•´çš„èƒ½æºæ•°æ®é¢„å¤„ç†æµç¨‹ - æ”¯æŒå¤šæ¥¼å±‚å¤šå¹´ä»½æ•°æ®
    
    Args:
        raw_data_dir: åŸå§‹æ•°æ®ç›®å½•è·¯å¾„ï¼ˆé»˜è®¤ä¸º data/rawï¼‰
        output_dir: è¾“å‡ºæ•°æ®ç›®å½•è·¯å¾„ï¼ˆé»˜è®¤ä¸º data/processedï¼‰
        year: å¹´ä»½ï¼ˆ'2018', '2019', æˆ– None è¡¨ç¤ºæ‰€æœ‰å¹´ä»½ï¼‰
        floors: æ¥¼å±‚åˆ—è¡¨ï¼ˆä¾‹å¦‚ [1, 2, 3] æˆ– None è¡¨ç¤ºæ‰€æœ‰æ¥¼å±‚ï¼‰
        output_file: è¾“å‡ºæ–‡ä»¶åï¼ˆé»˜è®¤æ ¹æ®å¹´ä»½è‡ªåŠ¨ç”Ÿæˆï¼‰
        
    Returns:
        å¤„ç†åçš„ DataFrame
    """
    print("\n" + "ğŸš€ " + "="*76)
    print("ğŸ  å®¶åº­å¾®ç½‘èƒ½æºä¼˜åŒ–ç³»ç»Ÿ - æ•°æ®é¢„å¤„ç†æµç¨‹ï¼ˆå¤šæ¥¼å±‚ç‰ˆæœ¬ï¼‰")
    print("="*78 + "\n")
    
    # åˆå§‹åŒ–å¤„ç†å™¨
    processor = EnergyDataProcessor(raw_data_dir, output_dir)
    
    # è‡ªåŠ¨å‘ç°æ‰€æœ‰æ•°æ®æ–‡ä»¶
    import glob
    import os
    
    pattern = os.path.join(processor.raw_data_dir, '*.csv')
    all_files = sorted(glob.glob(pattern))
    all_files = [f for f in all_files if not f.endswith('.gitkeep')]
    
    print(f"ğŸ“‚ å‘ç° {len(all_files)} ä¸ªæ•°æ®æ–‡ä»¶")
    
    # è¿‡æ»¤æ–‡ä»¶
    selected_files = []
    for file_path in all_files:
        filename = os.path.basename(file_path)
        if not filename.endswith('.csv'):
            continue
        
        # æå–å¹´ä»½å’Œæ¥¼å±‚
        try:
            file_year = filename[:4]
            floor_num = int(filename.replace(file_year, '').replace('Floor', '').replace('.csv', ''))
            
            # åº”ç”¨è¿‡æ»¤æ¡ä»¶
            if year and file_year != year:
                continue
            if floors and floor_num not in floors:
                continue
            
            selected_files.append((file_path, file_year, floor_num))
        except:
            continue
    
    if not selected_files:
        raise ValueError("æœªæ‰¾åˆ°ç¬¦åˆæ¡ä»¶çš„æ•°æ®æ–‡ä»¶")
    
    print(f"âœ… é€‰æ‹©äº† {len(selected_files)} ä¸ªæ–‡ä»¶è¿›è¡Œå¤„ç†:")
    for file_path, file_year, floor_num in selected_files:
        print(f"   - {file_year}Floor{floor_num}.csv")
    
    # Step 1: è¯»å–æ‰€æœ‰æ•°æ®
    print("\nã€æ­¥éª¤ 1/6ã€‘è¯»å–åŸå§‹æ•°æ®")
    print("-" * 80)
    
    all_floors_data = []
    temperature_data = None
    
    for file_path, file_year, floor_num in selected_files:
        try:
            df = processor.read_csv_with_date(Path(file_path))
            
            # ç¡®ä¿ Date åˆ—æ˜¯ datetime ç±»å‹ï¼Œä½¿ç”¨ errors='coerce' å¤„ç†å¼‚å¸¸å€¼
            df['Date'] = pd.to_datetime(df['Date'], errors='coerce')
            
            # åˆ é™¤ Date ä¸º NaT çš„è¡Œ
            invalid_dates = df['Date'].isna().sum()
            if invalid_dates > 0:
                print(f"   âš ï¸  å‘ç° {invalid_dates} è¡Œæ— æ•ˆæ—¥æœŸï¼Œå·²åˆ é™¤")
                df = df.dropna(subset=['Date'])
            
            # Step 2: ç‰¹å¾èšåˆ
            df = processor.aggregate_power_columns(df, f'{file_year}_F{floor_num}')
            
            # æå–æ¸©åº¦æ•°æ®ï¼ˆå¦‚æœæœ‰ï¼‰
            temp_columns = [col for col in df.columns if 'degC' in col]
            if temp_columns and temperature_data is None:
                df_temp = processor.extract_temperature(df.copy())
                temperature_data = df_temp[['Date', 'Temperature']].copy()
            
            # ä¿ç•™Dateå’Œæ€»è´Ÿè½½åˆ—
            load_col = f'Total_Load_{file_year}_F{floor_num}'
            all_floors_data.append(df[['Date', load_col]].copy())
            
        except Exception as e:
            print(f"   âŒ å¤„ç† {file_year}Floor{floor_num}.csv æ—¶å‡ºé”™: {str(e)}")
            print(f"   è·³è¿‡æ­¤æ–‡ä»¶ï¼Œç»§ç»­å¤„ç†å…¶ä»–æ–‡ä»¶...")
    
    print("\nã€æ­¥éª¤ 2/6ã€‘ç‰¹å¾èšåˆ")
    print("-" * 80)
    print(f"âœ“ å·²èšåˆ {len(all_floors_data)} ä¸ªæ¥¼å±‚çš„åŠŸç‡æ•°æ®")
    
    # Step 3: æ•°æ®åˆå¹¶
    print("\nã€æ­¥éª¤ 3/6ã€‘æ•°æ®åˆå¹¶")
    print("-" * 80)
    
    # åˆå¹¶æ‰€æœ‰æ¥¼å±‚æ•°æ®
    merged_df = all_floors_data[0]
    for df in all_floors_data[1:]:
        merged_df = pd.merge(merged_df, df, on='Date', how='inner')
    
    # åˆå¹¶æ¸©åº¦æ•°æ®
    if temperature_data is not None:
        merged_df = pd.merge(merged_df, temperature_data, on='Date', how='inner')
    
    # è®¡ç®—å…¨ç«™æ€»è´Ÿè½½
    load_columns = [col for col in merged_df.columns if col.startswith('Total_Load_')]
    merged_df['Site_Load'] = merged_df[load_columns].sum(axis=1)
    
    print(f"   âœ“ åˆå¹¶å®Œæˆï¼Œå…± {len(merged_df)} è¡Œæ•°æ®")
    print(f"   âœ“ å·²è®¡ç®— Site_Loadï¼ŒèŒƒå›´: {merged_df['Site_Load'].min():.2f} - {merged_df['Site_Load'].max():.2f} kW")
    
    # Step 4: é‡é‡‡æ ·
    print("\nã€æ­¥éª¤ 4/6ã€‘é‡é‡‡æ ·ä¸ºå°æ—¶çº§æ•°æ®")
    print("-" * 80)
    hourly_df = processor.resample_to_hourly(merged_df)
    
    # Step 5: ç‰¹å¾å·¥ç¨‹
    print("\nã€æ­¥éª¤ 5/6ã€‘ç‰¹å¾å·¥ç¨‹")
    print("-" * 80)
    hourly_df = processor.add_price_feature(hourly_df)
    hourly_df = processor.add_time_features(hourly_df)
    hourly_df = processor.add_advanced_features(hourly_df)
    
    # Step 6: ä¿å­˜æ•°æ®
    print("\nã€æ­¥éª¤ 6/6ã€‘ä¿å­˜å¤„ç†åçš„æ•°æ®")
    print("-" * 80)
    
    # è‡ªåŠ¨ç”Ÿæˆè¾“å‡ºæ–‡ä»¶å
    if output_file is None:
        if year:
            output_file = f'cleaned_energy_data_{year}.csv'
        else:
            output_file = 'cleaned_energy_data_all.csv'
    
    processor.save_processed_data(hourly_df, output_file)
    
    # æ‰“å°æ‘˜è¦
    processor.print_summary(hourly_df)
    
    return hourly_df


def preprocess_all_data(raw_data_dir: str = None, output_dir: str = None):
    """
    å¤„ç†æ‰€æœ‰å¹´ä»½å’Œæ¥¼å±‚çš„æ•°æ®
    
    Args:
        raw_data_dir: åŸå§‹æ•°æ®ç›®å½•
        output_dir: è¾“å‡ºç›®å½•
    """
    print("\n" + "="*80)
    print("ğŸŒŸ å¼€å§‹å¤„ç†æ‰€æœ‰æ•°æ®æ–‡ä»¶...")
    print("="*80 + "\n")
    
    # å¤„ç† 2018 å¹´æ‰€æœ‰æ¥¼å±‚
    print("\n" + "#"*80)
    print("# å¤„ç† 2018 å¹´æ•°æ®")
    print("#"*80)
    df_2018 = preprocess_energy_data(
        raw_data_dir=raw_data_dir,
        output_dir=output_dir,
        year='2018',
        output_file='cleaned_energy_data_2018.csv'
    )
    
    # å¤„ç† 2019 å¹´æ‰€æœ‰æ¥¼å±‚
    print("\n" + "#"*80)
    print("# å¤„ç† 2019 å¹´æ•°æ®")
    print("#"*80)
    df_2019 = preprocess_energy_data(
        raw_data_dir=raw_data_dir,
        output_dir=output_dir,
        year='2019',
        output_file='cleaned_energy_data_2019.csv'
    )
    
    # åˆå¹¶æ‰€æœ‰å¹´ä»½æ•°æ®ï¼ˆä½¿ç”¨ concat è€Œä¸æ˜¯ mergeï¼‰
    print("\n" + "#"*80)
    print("# åˆå¹¶æ‰€æœ‰å¹´ä»½æ•°æ®")
    print("#"*80)
    print("æ­£åœ¨åˆå¹¶ 2018 å’Œ 2019 å¹´æ•°æ®...")
    
    # ç¡®ä¿ä¸¤ä¸ªDataFrameæœ‰ç›¸åŒçš„åˆ—
    common_cols = [
        'Date', 'Site_Load', 'Temperature', 'Hour', 'Price', 'DayOfWeek',
        'Lag_1h', 'Lag_24h', 'Lag_168h',
        'Rolling_Mean_6h', 'Rolling_Std_6h', 'Rolling_Mean_24h',
        'Temp_x_Hour', 'Lag24_x_DayOfWeek'
    ]
    df_2018_subset = df_2018[common_cols].copy()
    df_2019_subset = df_2019[common_cols].copy()
    
    # ä½¿ç”¨ concat åˆå¹¶
    df_all = pd.concat([df_2018_subset, df_2019_subset], ignore_index=True)
    df_all = df_all.sort_values('Date').reset_index(drop=True)
    
    # ä¿å­˜åˆå¹¶åçš„æ•°æ®
    processor = EnergyDataProcessor(raw_data_dir, output_dir)
    processor.save_processed_data(df_all, 'cleaned_energy_data_all.csv')
    
    print(f"âœ“ åˆå¹¶å®Œæˆï¼Œæ€»å…± {len(df_all)} è¡Œæ•°æ®")
    print(f"  - æ—¥æœŸèŒƒå›´: {df_all['Date'].min()} åˆ° {df_all['Date'].max()}")
    
    print("\n" + "="*80)
    print("ğŸ‰ æ‰€æœ‰æ•°æ®å¤„ç†å®Œæˆï¼")
    print("="*80)
    print(f"\nğŸ“Š å¤„ç†ç»“æœæ±‡æ€»:")
    print(f"   - 2018å¹´æ•°æ®: {len(df_2018)} è¡Œ")
    print(f"   - 2019å¹´æ•°æ®: {len(df_2019)} è¡Œ")
    print(f"   - å…¨éƒ¨æ•°æ®: {len(df_all)} è¡Œ")
    print(f"\nğŸ“ è¾“å‡ºæ–‡ä»¶:")
    print(f"   - cleaned_energy_data_2018.csv")
    print(f"   - cleaned_energy_data_2019.csv")
    print(f"   - cleaned_energy_data_all.csv")
    print("\n")
    
    return df_2018, df_2019, df_all


if __name__ == '__main__':
    """
    ä¸»å‡½æ•° - æ‰§è¡Œå®Œæ•´çš„æ•°æ®é¢„å¤„ç†æµç¨‹
    """
    # å¤„ç†æ‰€æœ‰æ•°æ®
    preprocess_all_data()
    
    print("ğŸ‰ æ•°æ®é¢„å¤„ç†æµç¨‹å…¨éƒ¨å®Œæˆï¼")
    print(f"ğŸ“ å¤„ç†åçš„æ•°æ®å·²ä¿å­˜ï¼Œå¯ç”¨äºæ¨¡å‹è®­ç»ƒã€‚\n")
