"""
Google Cloud Storage æœåŠ¡
ç”¨äºä¸Šä¼ ã€ä¸‹è½½å’Œç®¡ç†æ–‡ä»¶
"""

from google.cloud import storage
from google.oauth2 import service_account
import os
import pandas as pd
import tempfile
from datetime import datetime, timedelta
from config import Config
from typing import Dict, Optional


class StorageService:
    """Cloud Storage æœåŠ¡ç±»"""
    
    def __init__(self, bucket_name=None):
        """
        åˆå§‹åŒ– Storage æœåŠ¡
        
        Args:
            bucket_name: å­˜å‚¨æ¡¶åç§°
        """
        self.project_id = os.getenv('GCP_PROJECT_ID') or Config.GCP_PROJECT_ID
        self.credentials = self._load_credentials()
        if self.credentials:
            self.client = storage.Client(project=self.project_id, credentials=self.credentials)
        else:
            if not self._is_running_in_gae():
                raise EnvironmentError(
                    "æœªæ£€æµ‹åˆ°æœ¬åœ° GCP å‡­è¯ã€‚è¯·è®¾ç½® GOOGLE_APPLICATION_CREDENTIALS æˆ– GCP_SERVICE_ACCOUNT_JSON ç¯å¢ƒå˜é‡ã€‚"
                )
            self.client = storage.Client(project=self.project_id)

        self.bucket_name = bucket_name or os.getenv('STORAGE_BUCKET_NAME') or Config.STORAGE_BUCKET_NAME
        self.bucket = self.client.bucket(self.bucket_name)

    def _load_credentials(self):
        """åœ¨æœ¬åœ°ç¯å¢ƒåŠ è½½æ˜¾å¼æœåŠ¡è´¦å·å‡­è¯"""
        # ä¼˜å…ˆä½¿ç”¨ JSON å­—ç¬¦ä¸² (CI/CD æˆ–å¯†é’¥ç®¡ç†æœåŠ¡å¸¸ç”¨)
        service_account_json = os.getenv('GCP_SERVICE_ACCOUNT_JSON')
        if service_account_json:
            try:
                import json
                info = json.loads(service_account_json)
                creds = service_account.Credentials.from_service_account_info(info)
                print("âœ… å·²é€šè¿‡ GCP_SERVICE_ACCOUNT_JSON åŠ è½½å‡­è¯")
                return creds
            except Exception as e:
                print(f"âŒ è§£æ GCP_SERVICE_ACCOUNT_JSON å¤±è´¥: {e}")
                return None

        credentials_path = os.getenv('GOOGLE_APPLICATION_CREDENTIALS')
        if not credentials_path:
            return None

        if not os.path.exists(credentials_path):
            print(f"âš ï¸  æŒ‡å®šçš„ GOOGLE_APPLICATION_CREDENTIALS è·¯å¾„ä¸å­˜åœ¨: {credentials_path}")
            return None

        try:
            creds = service_account.Credentials.from_service_account_file(credentials_path)
            print("âœ… å·²é€šè¿‡ GOOGLE_APPLICATION_CREDENTIALS åŠ è½½å‡­è¯")
            return creds
        except Exception as e:
            print(f"âŒ åŠ è½½æœ¬åœ°å‡­è¯å¤±è´¥: {e}")
            return None

    @staticmethod
    def _is_running_in_gae() -> bool:
        return bool(os.getenv('GAE_ENV') or os.getenv('K_SERVICE'))
    
    def upload_file(self, file_data, destination_path, content_type=None):
        """
        ä¸Šä¼ æ–‡ä»¶åˆ° Cloud Storage
        
        Args:
            file_data: æ–‡ä»¶æ•°æ® (bytes æˆ– file-like object)
            destination_path: ç›®æ ‡è·¯å¾„ (ä¾‹å¦‚: 'uploads/file.csv')
            content_type: æ–‡ä»¶ç±»å‹ (ä¾‹å¦‚: 'text/csv')
            
        Returns:
            str: æ–‡ä»¶çš„å…¬å¼€ URL
        """
        blob = self.bucket.blob(destination_path)
        
        if content_type:
            blob.content_type = content_type
        
        # ä¸Šä¼ æ–‡ä»¶
        if isinstance(file_data, bytes):
            blob.upload_from_string(file_data)
        else:
            blob.upload_from_file(file_data)
        
        return f"gs://{self.bucket_name}/{destination_path}"
    
    def download_file(self, source_path):
        """
        ä» Cloud Storage ä¸‹è½½æ–‡ä»¶
        
        Args:
            source_path: æ–‡ä»¶è·¯å¾„
            
        Returns:
            bytes: æ–‡ä»¶å†…å®¹
        """
        blob = self.bucket.blob(source_path)
        return blob.download_as_bytes()
    
    def delete_file(self, file_path):
        """
        åˆ é™¤æ–‡ä»¶
        
        Args:
            file_path: æ–‡ä»¶è·¯å¾„
        """
        blob = self.bucket.blob(file_path)
        blob.delete()
    
    def list_files(self, prefix=None):
        """
        åˆ—å‡ºæ–‡ä»¶
        
        Args:
            prefix: è·¯å¾„å‰ç¼€ (å¯é€‰)
            
        Returns:
            list: æ–‡ä»¶åˆ—è¡¨
        """
        blobs = self.bucket.list_blobs(prefix=prefix)
        return [blob.name for blob in blobs]
    
    def get_signed_url(self, file_path, expiration_minutes=60):
        """
        ç”Ÿæˆç­¾å URL (ä¸´æ—¶è®¿é—®é“¾æ¥)
        
        Args:
            file_path: æ–‡ä»¶è·¯å¾„
            expiration_minutes: è¿‡æœŸæ—¶é—´(åˆ†é’Ÿ)
            
        Returns:
            str: ç­¾å URL
        """
        blob = self.bucket.blob(file_path)
        url = blob.generate_signed_url(
            expiration=timedelta(minutes=expiration_minutes),
            method='GET'
        )
        return url

    def generate_upload_signed_url(self, destination_path, content_type, expiration_minutes=15):
        """
        ç”Ÿæˆä¸Šä¼ ç”¨çš„ç­¾å URL (PUT è¯·æ±‚)
        ä½¿ç”¨ Impersonated Credentials ç­¾åï¼Œé€‚ç”¨äº GAE ç¯å¢ƒ
        
        Args:
            destination_path: ç›®æ ‡è·¯å¾„
            content_type: æ–‡ä»¶ç±»å‹
            expiration_minutes: è¿‡æœŸæ—¶é—´(åˆ†é’Ÿ)
            
        Returns:
            str: ç­¾å URL
        """
        from google.auth import default, impersonated_credentials
        from google.cloud import storage
        
        # è·å–é»˜è®¤å‡­æ®å’Œé¡¹ç›® ID
        credentials, project = default()
        
        # è·å–æœåŠ¡è´¦å·é‚®ç®±
        service_account_email = f"{project}@appspot.gserviceaccount.com"
        
        try:
            # åˆ›å»º Impersonated Credentials
            # è¿™ä¼šè®©å½“å‰å‡­æ®(é»˜è®¤æœåŠ¡è´¦å·)å»æ‰®æ¼”å®ƒè‡ªå·±ï¼Œä»è€Œè·å–ç­¾åèƒ½åŠ›
            # éœ€è¦å¯ç”¨ IAM Service Account Credentials API
            target_credentials = impersonated_credentials.Credentials(
                source_credentials=credentials,
                target_principal=service_account_email,
                target_scopes=['https://www.googleapis.com/auth/cloud-platform'],
                lifetime=timedelta(minutes=expiration_minutes + 5)
            )
            
            # ä½¿ç”¨ Impersonated Credentials åˆ›å»ºä¸´æ—¶çš„ Storage Client
            # è¿™æ ·ç”Ÿæˆçš„ blob ä¼šè‡ªåŠ¨ä½¿ç”¨ IAM API è¿›è¡Œç­¾å
            temp_client = storage.Client(credentials=target_credentials, project=project)
            temp_bucket = temp_client.bucket(self.bucket_name)
            blob = temp_bucket.blob(destination_path)
            
            url = blob.generate_signed_url(
                expiration=timedelta(minutes=expiration_minutes),
                method='PUT',
                content_type=content_type,
                version='v4'
            )
            return url
        except Exception as e:
            print(f"Signed URL generation error: {e}")
            # å¦‚æœ IAM ç­¾åå¤±è´¥ï¼Œå°è¯•å›é€€åˆ°é»˜è®¤æ–¹æ³•ï¼ˆæœ¬åœ°å¼€å‘ç¯å¢ƒå¯èƒ½éœ€è¦ï¼‰
            try:
                blob = self.bucket.blob(destination_path)
                return blob.generate_signed_url(
                    expiration=timedelta(minutes=expiration_minutes),
                    method='PUT',
                    content_type=content_type,
                    version='v4'
                )
            except Exception as fallback_error:
                print(f"Fallback generation error: {fallback_error}")
                raise e
    
    def file_exists(self, file_path):
        """
        æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
        
        Args:
            file_path: æ–‡ä»¶è·¯å¾„
            
        Returns:
            bool: æ–‡ä»¶æ˜¯å¦å­˜åœ¨
        """
        blob = self.bucket.blob(file_path)
        return blob.exists()
    
    def append_and_trim_csv(
        self, 
        file_path: str, 
        new_row_dict: Dict, 
        max_rows: int = 5000
    ) -> bool:
        """
        æ™ºèƒ½ CSV ç®¡ç†: è¿½åŠ æ–°è¡Œå¹¶ä¿æŒæ»‘åŠ¨çª—å£
        
        æ­¤æ–¹æ³•ä¸“ä¸º GAE F1 ç¯å¢ƒè®¾è®¡ï¼Œä½¿ç”¨ /tmp ç›®å½•å¤„ç†æ–‡ä»¶ï¼Œ
        é¿å…å†…å­˜æº¢å‡ºã€‚å®ç°å¢é‡æ•°æ®è¿½åŠ å’Œè‡ªåŠ¨ä¿®å‰ªæ—§æ•°æ®ã€‚
        
        Args:
            file_path: Firebase Storage ä¸­çš„ CSV æ–‡ä»¶è·¯å¾„ (ä¾‹å¦‚: 'data/processed/cleaned_energy_data_all.csv')
            new_row_dict: è¦è¿½åŠ çš„æ–°è¡Œæ•°æ® (å­—å…¸æ ¼å¼)
            max_rows: æœ€å¤§ä¿ç•™è¡Œæ•°ï¼Œè¶…è¿‡åˆ™åˆ é™¤æœ€æ—§çš„æ•°æ® (é»˜è®¤ 5000 è¡Œçº¦ 7 ä¸ªæœˆ)
            
        Returns:
            bool: æ“ä½œæ˜¯å¦æˆåŠŸ
            
        Raises:
            Exception: æ–‡ä»¶æ“ä½œå¤±è´¥æ—¶æŠ›å‡ºå¼‚å¸¸
            
        Example:
            >>> storage = StorageService()
            >>> new_data = {
            ...     'Date': '2024-11-24 08:00:00',
            ...     'Hour': 8,
            ...     'DayOfWeek': 6,
            ...     'Temperature': 25.5,
            ...     'Price': 0.6,
            ...     'Site_Load': 1250.0
            ... }
            >>> storage.append_and_trim_csv('data/processed/cleaned_energy_data_all.csv', new_data)
        """
        temp_file_path = None
        
        try:
            print(f"ğŸ“ å¼€å§‹ CSV è¿½åŠ æ“ä½œ: {file_path}")
            
            # ä½¿ç”¨ /tmp ç›®å½• (GAE å”¯ä¸€å¯å†™ç›®å½•)
            temp_file_path = os.path.join(tempfile.gettempdir(), f'temp_csv_{os.getpid()}.csv')
            
            # 1. æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
            blob = self.bucket.blob(file_path)
            file_exists = blob.exists()
            
            if file_exists:
                print(f"   âœ“ æ–‡ä»¶å­˜åœ¨ï¼Œä¸‹è½½åˆ°: {temp_file_path}")
                
                # 2. ä¸‹è½½ç°æœ‰æ–‡ä»¶åˆ° /tmp
                blob.download_to_filename(temp_file_path)
                
                # 3. è¯»å– CSV (ä½¿ç”¨ chunksize é¿å…å¤§æ–‡ä»¶å†…å­˜é—®é¢˜)
                try:
                    df = pd.read_csv(temp_file_path)
                    original_rows = len(df)
                    print(f"   âœ“ è¯»å–æˆåŠŸ: {original_rows} è¡Œ")
                    
                    # 4. ä¿®å‰ªæ•°æ® (ä¿ç•™æœ€æ–°çš„ max_rows è¡Œ)
                    if original_rows >= max_rows:
                        df = df.iloc[-(max_rows - 1):]  # ä¿ç•™æœ€æ–°çš„ max_rows-1 è¡Œï¼Œä¸ºæ–°è¡Œç•™ç©ºé—´
                        print(f"   âœ‚ï¸  ä¿®å‰ªæ•°æ®: {original_rows} â†’ {len(df)} è¡Œ")
                    
                except pd.errors.EmptyDataError:
                    print(f"   âš ï¸  æ–‡ä»¶ä¸ºç©ºï¼Œåˆ›å»ºæ–° DataFrame")
                    df = pd.DataFrame()
                    
            else:
                print(f"   â„¹ï¸  æ–‡ä»¶ä¸å­˜åœ¨ï¼Œåˆ›å»ºæ–°æ–‡ä»¶")
                df = pd.DataFrame()
            
            # 5. è¿½åŠ æ–°è¡Œ
            new_row_df = pd.DataFrame([new_row_dict])
            df = pd.concat([df, new_row_df], ignore_index=True)
            print(f"   âœ“ è¿½åŠ æ–°è¡Œï¼Œå½“å‰æ€»è¡Œæ•°: {len(df)}")
            
            # 6. ä¿å­˜åˆ°ä¸´æ—¶æ–‡ä»¶
            df.to_csv(temp_file_path, index=False)
            print(f"   âœ“ ä¿å­˜åˆ°ä¸´æ—¶æ–‡ä»¶")
            
            # 7. ä¸Šä¼ å› Firebase Storage
            blob.upload_from_filename(temp_file_path, content_type='text/csv')
            print(f"   âœ“ ä¸Šä¼ åˆ° Firebase Storage: gs://{self.bucket_name}/{file_path}")
            
            return True
            
        except Exception as e:
            print(f"   âŒ CSV è¿½åŠ å¤±è´¥: {str(e)}")
            raise Exception(f"Failed to append and trim CSV: {str(e)}")
            
        finally:
            # 8. æ¸…ç†ä¸´æ—¶æ–‡ä»¶
            if temp_file_path and os.path.exists(temp_file_path):
                try:
                    os.remove(temp_file_path)
                    print(f"   ğŸ§¹ æ¸…ç†ä¸´æ—¶æ–‡ä»¶")
                except Exception as e:
                    print(f"   âš ï¸  æ¸…ç†ä¸´æ—¶æ–‡ä»¶å¤±è´¥: {str(e)}")
    
    def download_to_temp(self, file_path: str) -> Optional[str]:
        """
        ä¸‹è½½æ–‡ä»¶åˆ° /tmp ç›®å½•å¹¶è¿”å›ä¸´æ—¶æ–‡ä»¶è·¯å¾„
        
        Args:
            file_path: Firebase Storage ä¸­çš„æ–‡ä»¶è·¯å¾„
            
        Returns:
            str: ä¸´æ—¶æ–‡ä»¶çš„ç»å¯¹è·¯å¾„ï¼Œå¦‚æœå¤±è´¥è¿”å› None
        """
        try:
            blob = self.bucket.blob(file_path)
            
            if not blob.exists():
                print(f"âŒ æ–‡ä»¶ä¸å­˜åœ¨: {file_path}")
                return None
            
            # ç”Ÿæˆä¸´æ—¶æ–‡ä»¶è·¯å¾„
            file_extension = os.path.splitext(file_path)[1]
            temp_file_path = os.path.join(
                tempfile.gettempdir(), 
                f'download_{os.getpid()}_{os.path.basename(file_path)}'
            )
            
            # ä¸‹è½½æ–‡ä»¶
            blob.download_to_filename(temp_file_path)
            print(f"âœ“ ä¸‹è½½æ–‡ä»¶åˆ°: {temp_file_path}")
            
            return temp_file_path
            
        except Exception as e:
            print(f"âŒ ä¸‹è½½æ–‡ä»¶å¤±è´¥: {str(e)}")
            return None
