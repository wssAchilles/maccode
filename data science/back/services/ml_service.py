"""
æœºå™¨å­¦ä¹ æœåŠ¡æ¨¡å— - èƒ½æºè´Ÿè½½é¢„æµ‹
ML Service Module for Energy Load Prediction

ä½¿ç”¨éšæœºæ£®æ—å›å½’æ¨¡å‹é¢„æµ‹æœªæ¥24å°æ—¶çš„èƒ½æºè´Ÿè½½
"""

import pandas as pd
import numpy as np
import joblib
import os
import tempfile
from pathlib import Path
from typing import List, Dict, Optional, Union
from datetime import datetime, timedelta
from sklearn.ensemble import RandomForestRegressor
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_absolute_error, mean_squared_error
import warnings

warnings.filterwarnings('ignore')


class EnergyPredictor:
    """
    èƒ½æºè´Ÿè½½é¢„æµ‹å™¨
    
    ä½¿ç”¨éšæœºæ£®æ—æ¨¡å‹é¢„æµ‹æœªæ¥24å°æ—¶çš„èƒ½æºè´Ÿè½½
    æ”¯æŒæ¨¡å‹è®­ç»ƒã€ä¿å­˜ã€åŠ è½½å’Œæ¨ç†
    """
    
    def __init__(self, model_path: str = None):
        """
        åˆå§‹åŒ–é¢„æµ‹å™¨
        
        Args:
            model_path: æœ¬åœ°å…œåº•æ¨¡å‹è·¯å¾„ï¼ˆå¯é€‰ï¼‰ï¼Œä¸»è¦ä» Firebase Storage åŠ è½½
        """
        # è·å–é¡¹ç›®æ ¹ç›®å½•
        self.script_dir = Path(__file__).parent  # services ç›®å½•
        self.back_dir = self.script_dir.parent  # back ç›®å½•
        
        # Firebase Storage æ¨¡å‹è·¯å¾„ï¼ˆä¸»è¦å­˜å‚¨ä½ç½®ï¼‰
        self.firebase_model_path = 'models/rf_model.joblib'
        
        # æœ¬åœ°å…œåº•æ¨¡å‹è·¯å¾„ï¼ˆéƒ¨ç½²åŒ…ä¸­è‡ªå¸¦çš„æ¨¡å‹ï¼Œä»…ç”¨äºé¦–æ¬¡åŠ è½½ï¼‰
        if model_path:
            self.local_model_path = Path(model_path)
        else:
            self.local_model_path = self.back_dir / 'models' / 'rf_model.joblib'
        
        # åˆå§‹åŒ– StorageService
        from services.storage_service import StorageService
        self.storage_service = StorageService()
        
        # åˆå§‹åŒ–æ¨¡å‹
        self.model: Optional[RandomForestRegressor] = None
        
        # ç‰¹å¾åˆ—è¡¨
        self.feature_columns = ['Hour', 'DayOfWeek', 'Temperature', 'Price']
        self.target_column = 'Site_Load'
        
        print(f"ğŸ“ Firebase Storage æ¨¡å‹è·¯å¾„: {self.firebase_model_path}")
        print(f"ğŸ“ æœ¬åœ°å…œåº•æ¨¡å‹è·¯å¾„: {self.local_model_path}")
    
    def _get_price(self, hour: int) -> float:
        """
        æ ¹æ®å°æ—¶è¿”å›å³°è°·ç”µä»·
        
        Args:
            hour: å°æ—¶ (0-23)
            
        Returns:
            ç”µä»· (å…ƒ/kWh)
        """
        if 8 <= hour < 18:
            return 0.6  # å¹³æ—¶
        elif 18 <= hour < 22:
            return 1.0  # å³°æ—¶
        else:
            return 0.3  # è°·æ—¶
    
    def _save_model_metadata(self, metadata: dict) -> bool:
        """
        ä¿å­˜æ¨¡å‹å…ƒæ•°æ®åˆ° Firebase Storage (JSON æ–‡ä»¶)
        
        Args:
            metadata: æ¨¡å‹å…ƒæ•°æ®å­—å…¸
            
        Returns:
            æ˜¯å¦ä¿å­˜æˆåŠŸ
        """
        try:
            import json
            from datetime import datetime
            
            # æ·»åŠ æ›´æ–°æ—¶é—´æˆ³
            metadata['updated_at'] = datetime.now().isoformat()
            
            # è½¬æ¢ä¸º JSON å­—ç¬¦ä¸²
            json_data = json.dumps(metadata, indent=2, ensure_ascii=False)
            
            # ä¸Šä¼ åˆ° Storage (ä½¿ç”¨ä¸´æ—¶æ–‡ä»¶ç¡®ä¿ Content-Type æ­£ç¡®)
            import tempfile
            metadata_path = 'models/model_metadata.json'
            
            with tempfile.NamedTemporaryFile(mode='w', suffix='.json', delete=False, encoding='utf-8') as f:
                f.write(json_data)
                temp_path = f.name
            
            try:
                with open(temp_path, 'rb') as f:
                    self.storage_service.bucket.blob(metadata_path).upload_from_file(
                        f, 
                        content_type='application/json'
                    )
            finally:
                import os
                os.unlink(temp_path)
            
            print(f"   âœ“ æ¨¡å‹å…ƒæ•°æ®å·²ä¿å­˜åˆ° Firebase Storage: {metadata_path}")
            return True
            
        except Exception as e:
            print(f"   âŒ ä¿å­˜æ¨¡å‹å…ƒæ•°æ®å¤±è´¥: {str(e)}")
            return False
    
    @staticmethod
    def get_model_metadata() -> Optional[dict]:
        """
        ä» Firebase Storage è·å–æ¨¡å‹å…ƒæ•°æ® (JSON æ–‡ä»¶)
        
        Returns:
            æ¨¡å‹å…ƒæ•°æ®å­—å…¸ï¼Œå¦‚æœä¸å­˜åœ¨è¿”å› None
        """
        try:
            import json
            from services.storage_service import StorageService
            
            # åˆ›å»º Storage æœåŠ¡å®ä¾‹
            storage = StorageService()
            
            # ä¸‹è½½å…ƒæ•°æ® JSON
            metadata_path = 'models/model_metadata.json'
            json_bytes = storage.download_file(metadata_path)
            
            # è§£æ JSON
            metadata = json.loads(json_bytes.decode('utf-8'))
            return metadata
                
        except Exception as e:
            print(f"è·å–æ¨¡å‹å…ƒæ•°æ®å¤±è´¥: {str(e)}")
            return None
    
    def train_model(
        self, 
        data_path: str = None,
        n_estimators: int = 100,
        test_size: float = 0.2,
        random_state: int = 42,
        use_firebase_storage: bool = True
    ) -> Dict[str, float]:
        """
        è®­ç»ƒéšæœºæ£®æ—æ¨¡å‹
        
        Args:
            data_path: æ•°æ®æ–‡ä»¶è·¯å¾„ï¼Œé»˜è®¤ä¸º data/processed/cleaned_energy_data_all.csv
            n_estimators: éšæœºæ£®æ—æ ‘çš„æ•°é‡
            test_size: æµ‹è¯•é›†æ¯”ä¾‹
            random_state: éšæœºç§å­
            use_firebase_storage: æ˜¯å¦ä» Firebase Storage ä¸‹è½½æ•°æ® (GAE ç¯å¢ƒå¿…é¡»ä¸º True)
            
        Returns:
            åŒ…å«è¯„ä¼°æŒ‡æ ‡çš„å­—å…¸ (MAE, RMSE)
        """
        print("\n" + "="*80)
        print("ğŸš€ å¼€å§‹è®­ç»ƒèƒ½æºè´Ÿè½½é¢„æµ‹æ¨¡å‹")
        print("="*80 + "\n")
        
        temp_data_path = None
        
        try:
            # ä» Firebase Storage ä¸‹è½½æ•°æ®
            if use_firebase_storage:
                print("ğŸ“¥ ä» Firebase Storage ä¸‹è½½è®­ç»ƒæ•°æ®...")
                from services.storage_service import StorageService
                
                storage_service = StorageService()
                firebase_path = data_path or 'data/processed/cleaned_energy_data_all.csv'
                
                temp_data_path = storage_service.download_to_temp(firebase_path)
                
                if temp_data_path is None:
                    raise FileNotFoundError(f"æ— æ³•ä» Firebase Storage ä¸‹è½½æ•°æ®: {firebase_path}")
                
                data_path = temp_data_path
                print(f"   âœ“ æ•°æ®å·²ä¸‹è½½åˆ°: {data_path}")
            else:
                # æœ¬åœ°æ–‡ä»¶æ¨¡å¼ (å¼€å‘ç¯å¢ƒ)
                if data_path is None:
                    # å°è¯•å¤šä¸ªå¯èƒ½çš„è·¯å¾„
                    possible_paths = [
                        self.back_dir.parent / 'data' / 'processed' / 'cleaned_energy_data_all.csv',
                        self.back_dir / 'data' / 'processed' / 'cleaned_energy_data_all.csv',
                    ]
                    data_path = None
                    for path in possible_paths:
                        if path.exists():
                            data_path = path
                            break
                    if data_path is None:
                        data_path = possible_paths[0]  # ä½¿ç”¨ç¬¬ä¸€ä¸ªä½œä¸ºé»˜è®¤
                else:
                    data_path = Path(data_path)
            
            # è¯»å–æ•°æ®
            print(f"ğŸ“– è¯»å–æ•°æ®: {data_path}")
            try:
                df = pd.read_csv(data_path, parse_dates=['Date'])
                print(f"   âœ“ æ•°æ®è¯»å–æˆåŠŸ: {len(df)} è¡Œ Ã— {len(df.columns)} åˆ—")
            except FileNotFoundError:
                raise FileNotFoundError(f"æ•°æ®æ–‡ä»¶ä¸å­˜åœ¨: {data_path}")
            except Exception as e:
                raise Exception(f"è¯»å–æ•°æ®æ—¶å‡ºé”™: {str(e)}")
            
            # æ£€æŸ¥å¿…éœ€åˆ—
            required_cols = self.feature_columns + [self.target_column]
            missing_cols = [col for col in required_cols if col not in df.columns]
            if missing_cols:
                raise ValueError(f"æ•°æ®ç¼ºå°‘å¿…éœ€åˆ—: {missing_cols}")
            
            # å¤„ç†ç¼ºå¤±å€¼
            print(f"\nğŸ” æ£€æŸ¥æ•°æ®è´¨é‡...")
            null_counts = df[required_cols].isnull().sum()
            if null_counts.sum() > 0:
                print(f"   âš ï¸  å‘ç°ç¼ºå¤±å€¼:")
                for col, count in null_counts[null_counts > 0].items():
                    print(f"      - {col}: {count} ä¸ª")
                
                # å¯¹äº Temperatureï¼Œä½¿ç”¨å‡å€¼å¡«å……
                if 'Temperature' in null_counts and null_counts['Temperature'] > 0:
                    mean_temp = df['Temperature'].mean()
                    df['Temperature'].fillna(mean_temp, inplace=True)
                    print(f"   âœ“ Temperature ç¼ºå¤±å€¼å·²ç”¨å‡å€¼å¡«å……: {mean_temp:.2f}Â°C")
            else:
                print(f"   âœ“ æ— ç¼ºå¤±å€¼")
            
            # å‡†å¤‡ç‰¹å¾å’Œç›®æ ‡å˜é‡
            print(f"\nğŸ“Š å‡†å¤‡è®­ç»ƒæ•°æ®...")
            X = df[self.feature_columns].copy()
            y = df[self.target_column].copy()
            
            print(f"   - ç‰¹å¾åˆ—: {self.feature_columns}")
            print(f"   - ç›®æ ‡å˜é‡: {self.target_column}")
            print(f"   - æ•°æ®å½¢çŠ¶: X={X.shape}, y={y.shape}")
            
            # åˆ’åˆ†è®­ç»ƒé›†å’Œæµ‹è¯•é›†
            print(f"\nâœ‚ï¸  åˆ’åˆ†æ•°æ®é›† (è®­ç»ƒé›†: {int((1-test_size)*100)}%, æµ‹è¯•é›†: {int(test_size*100)}%)...")
            X_train, X_test, y_train, y_test = train_test_split(
                X, y, test_size=test_size, random_state=random_state
            )
            
            print(f"   - è®­ç»ƒé›†: {X_train.shape[0]} æ ·æœ¬")
            print(f"   - æµ‹è¯•é›†: {X_test.shape[0]} æ ·æœ¬")
            
            # è®­ç»ƒæ¨¡å‹
            print(f"\nğŸŒ² è®­ç»ƒéšæœºæ£®æ—æ¨¡å‹ (n_estimators={n_estimators})...")
            self.model = RandomForestRegressor(
                n_estimators=n_estimators,
                random_state=random_state,
                n_jobs=-1,  # ä½¿ç”¨æ‰€æœ‰CPUæ ¸å¿ƒ
                verbose=0
            )
            
            self.model.fit(X_train, y_train)
            print(f"   âœ“ æ¨¡å‹è®­ç»ƒå®Œæˆ!")
            
            # è¯„ä¼°æ¨¡å‹
            print(f"\nğŸ“ˆ è¯„ä¼°æ¨¡å‹æ€§èƒ½...")
            
            # è®­ç»ƒé›†é¢„æµ‹
            y_train_pred = self.model.predict(X_train)
            train_mae = mean_absolute_error(y_train, y_train_pred)
            train_rmse = np.sqrt(mean_squared_error(y_train, y_train_pred))
            
            # æµ‹è¯•é›†é¢„æµ‹
            y_test_pred = self.model.predict(X_test)
            test_mae = mean_absolute_error(y_test, y_test_pred)
            test_rmse = np.sqrt(mean_squared_error(y_test, y_test_pred))
            
            print(f"\n   è®­ç»ƒé›†æ€§èƒ½:")
            print(f"      - MAE:  {train_mae:.2f} kW")
            print(f"      - RMSE: {train_rmse:.2f} kW")
            
            print(f"\n   æµ‹è¯•é›†æ€§èƒ½:")
            print(f"      - MAE:  {test_mae:.2f} kW")
            print(f"      - RMSE: {test_rmse:.2f} kW")
            
            # ç‰¹å¾é‡è¦æ€§
            print(f"\nğŸ” ç‰¹å¾é‡è¦æ€§:")
            feature_importance = pd.DataFrame({
                'Feature': self.feature_columns,
                'Importance': self.model.feature_importances_
            }).sort_values('Importance', ascending=False)
            
            for _, row in feature_importance.iterrows():
                print(f"      - {row['Feature']}: {row['Importance']:.4f}")
            
            # ä¿å­˜æ¨¡å‹åˆ° Firebase Storage
            print(f"\nğŸ’¾ ä¿å­˜æ¨¡å‹åˆ° Firebase Storage: {self.firebase_model_path}")
            temp_model_path = None
            try:
                # Step A: åˆ›å»ºä¸´æ—¶æ–‡ä»¶
                with tempfile.NamedTemporaryFile(mode='wb', suffix='.joblib', delete=False) as tmp_file:
                    temp_model_path = tmp_file.name
                    print(f"   - ä¸´æ—¶æ–‡ä»¶: {temp_model_path}")
                
                # Step B: ä¿å­˜æ¨¡å‹åˆ°ä¸´æ—¶æ–‡ä»¶
                joblib.dump(self.model, temp_model_path)
                print(f"   âœ“ æ¨¡å‹å·²ä¿å­˜åˆ°ä¸´æ—¶æ–‡ä»¶")
                
                # Step C: ä¸Šä¼ åˆ° Firebase Storage
                with open(temp_model_path, 'rb') as f:
                    self.storage_service.upload_file(
                        file_data=f,
                        destination_path=self.firebase_model_path,
                        content_type='application/octet-stream'
                    )
                print(f"   âœ“ æ¨¡å‹å·²ä¸Šä¼ åˆ° Firebase Storage")
                
            except Exception as e:
                print(f"   âŒ æ¨¡å‹ä¿å­˜å¤±è´¥: {str(e)}")
                raise
            finally:
                # Step D: æ¸…ç†ä¸´æ—¶æ–‡ä»¶
                if temp_model_path and os.path.exists(temp_model_path):
                    try:
                        os.remove(temp_model_path)
                        print(f"   ğŸ§¹ å·²æ¸…ç†ä¸´æ—¶æ¨¡å‹æ–‡ä»¶")
                    except Exception as e:
                        print(f"   âš ï¸  æ¸…ç†ä¸´æ—¶æ¨¡å‹æ–‡ä»¶å¤±è´¥: {str(e)}")
            
            print("\n" + "="*80)
            print("âœ… æ¨¡å‹è®­ç»ƒå®Œæˆ!")
            print("="*80 + "\n")
            
            # ä¿å­˜æ¨¡å‹å…ƒæ•°æ®åˆ° Firestore (å…¨å±€å…ƒæ•°æ®)
            try:
                self._save_model_metadata({
                    'model_type': 'Random Forest Regressor',
                    'model_version': datetime.now().strftime('%Y%m%d_%H%M%S'),
                    'trained_at': datetime.now().isoformat(),
                    'metrics': {
                        'train_mae': float(train_mae),
                        'train_rmse': float(train_rmse),
                        'test_mae': float(test_mae),
                        'test_rmse': float(test_rmse)
                    },
                    'training_samples': len(df),
                    'data_source': 'CAISO Real-Time Stream',
                    'feature_importance': feature_importance.to_dict('records'),
                    'model_path': self.firebase_model_path,
                    'status': 'active'
                })
            except Exception as e:
                print(f"   âš ï¸  ä¿å­˜æ¨¡å‹å…ƒæ•°æ®å¤±è´¥: {str(e)}")
            
            # è¿”å›è¯„ä¼°æŒ‡æ ‡
            return {
                'train_mae': train_mae,
                'train_rmse': train_rmse,
                'test_mae': test_mae,
                'test_rmse': test_rmse,
                'feature_importance': feature_importance.to_dict('records')
            }
        
        finally:
            # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
            if temp_data_path and os.path.exists(temp_data_path):
                try:
                    os.remove(temp_data_path)
                    print(f"ğŸ§¹ æ¸…ç†ä¸´æ—¶è®­ç»ƒæ•°æ®æ–‡ä»¶")
                except Exception as e:
                    print(f"âš ï¸  æ¸…ç†ä¸´æ—¶æ–‡ä»¶å¤±è´¥: {str(e)}")
    
    def load_model(self) -> bool:
        """
        åŠ è½½å·²ä¿å­˜çš„æ¨¡å‹ï¼ˆä¼˜å…ˆä» Firebase Storageï¼‰
        
        Returns:
            æ˜¯å¦åŠ è½½æˆåŠŸ
            
        Raises:
            FileNotFoundError: æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨
            Exception: åŠ è½½æ¨¡å‹æ—¶å‡ºé”™
        """
        print(f"ğŸ“‚ åŠ è½½æ¨¡å‹...")
        temp_model_path = None
        
        try:
            # Step A: æ£€æŸ¥ Firebase Storage ä¸­æ˜¯å¦å­˜åœ¨æ¨¡å‹
            print(f"   - æ£€æŸ¥ Firebase Storage: {self.firebase_model_path}")
            
            if self.storage_service.file_exists(self.firebase_model_path):
                print(f"   âœ“ Firebase Storage ä¸­å­˜åœ¨æ¨¡å‹")
                
                # Step B: ä¸‹è½½åˆ°ä¸´æ—¶ç›®å½•
                temp_model_path = self.storage_service.download_to_temp(self.firebase_model_path)
                
                if temp_model_path is None:
                    raise Exception("ä» Firebase Storage ä¸‹è½½æ¨¡å‹å¤±è´¥")
                
                print(f"   âœ“ æ¨¡å‹å·²ä¸‹è½½åˆ°: {temp_model_path}")
                
                # Step C: ä»ä¸´æ—¶æ–‡ä»¶åŠ è½½æ¨¡å‹
                self.model = joblib.load(temp_model_path)
                print(f"   âœ“ æ¨¡å‹åŠ è½½æˆåŠŸ (æ¥æº: Firebase Storage)")
                return True
            
            else:
                # Step D: Firebase ä¸­æ²¡æœ‰æ¨¡å‹ï¼Œå°è¯•åŠ è½½æœ¬åœ°å…œåº•æ¨¡å‹
                print(f"   âš ï¸  Firebase Storage ä¸­æ— æ¨¡å‹ï¼Œå°è¯•åŠ è½½æœ¬åœ°å…œåº•æ¨¡å‹")
                
                if not self.local_model_path.exists():
                    raise FileNotFoundError(
                        f"æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨:\n"
                        f"  - Firebase Storage: {self.firebase_model_path} (ä¸å­˜åœ¨)\n"
                        f"  - æœ¬åœ°è·¯å¾„: {self.local_model_path} (ä¸å­˜åœ¨)\n"
                        f"è¯·å…ˆè°ƒç”¨ train_model() è®­ç»ƒæ¨¡å‹ã€‚"
                    )
                
                self.model = joblib.load(self.local_model_path)
                print(f"   âœ“ æ¨¡å‹åŠ è½½æˆåŠŸ (æ¥æº: æœ¬åœ°å…œåº•æ–‡ä»¶)")
                return True
        
        except Exception as e:
            raise Exception(f"åŠ è½½æ¨¡å‹æ—¶å‡ºé”™: {str(e)}")
        
        finally:
            # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
            if temp_model_path and os.path.exists(temp_model_path):
                try:
                    os.remove(temp_model_path)
                    print(f"   ğŸ§¹ å·²æ¸…ç†ä¸´æ—¶æ¨¡å‹æ–‡ä»¶")
                except Exception as e:
                    print(f"   âš ï¸  æ¸…ç†ä¸´æ—¶æ¨¡å‹æ–‡ä»¶å¤±è´¥: {str(e)}")
    
    def predict_next_24h(
        self,
        start_time: Union[str, datetime],
        temp_forecast_list: Optional[List[float]] = None
    ) -> List[Dict[str, Union[datetime, float]]]:
        """
        é¢„æµ‹æœªæ¥24å°æ—¶çš„èƒ½æºè´Ÿè½½
        
        Args:
            start_time: å¼€å§‹æ—¶é—´ï¼ˆå­—ç¬¦ä¸²æ ¼å¼ 'YYYY-MM-DD HH:00:00' æˆ– datetime å¯¹è±¡ï¼‰
            temp_forecast_list: æœªæ¥24å°æ—¶çš„æ¸©åº¦é¢„æµ‹åˆ—è¡¨ï¼Œå¦‚æœä¸ºNoneåˆ™ä½¿ç”¨é»˜è®¤å€¼25.0Â°C
            
        Returns:
            åŒ…å«é¢„æµ‹ç»“æœçš„å­—å…¸åˆ—è¡¨ï¼Œæ¯ä¸ªå­—å…¸åŒ…å«:
                - datetime: æ—¶é—´æˆ³
                - predicted_load: é¢„æµ‹è´Ÿè½½ (kW)
                - temperature: æ¸©åº¦ (Â°C)
                - price: ç”µä»· (å…ƒ/kWh)
                - hour: å°æ—¶ (0-23)
                - day_of_week: æ˜ŸæœŸå‡  (0-6)
                
        Raises:
            ValueError: æ¨¡å‹æœªåŠ è½½æˆ–å‚æ•°é”™è¯¯
        """
        # æ£€æŸ¥æ¨¡å‹æ˜¯å¦å·²åŠ è½½
        if self.model is None:
            raise ValueError(
                "æ¨¡å‹æœªåŠ è½½ï¼Œè¯·å…ˆè°ƒç”¨ load_model() æˆ– train_model()"
            )
        
        # è½¬æ¢å¼€å§‹æ—¶é—´
        if isinstance(start_time, str):
            start_time = pd.to_datetime(start_time)
        
        print(f"\nğŸ”® é¢„æµ‹æœªæ¥24å°æ—¶è´Ÿè½½ (ä» {start_time} å¼€å§‹)...")
        
        # å¤„ç†æ¸©åº¦é¢„æµ‹
        if temp_forecast_list is None:
            print(f"   âš ï¸  æœªæä¾›æ¸©åº¦é¢„æµ‹ï¼Œä½¿ç”¨é»˜è®¤å€¼ 25.0Â°C")
            temp_forecast_list = [25.0] * 24
        elif len(temp_forecast_list) != 24:
            raise ValueError(
                f"æ¸©åº¦é¢„æµ‹åˆ—è¡¨é•¿åº¦å¿…é¡»ä¸º24ï¼Œå½“å‰ä¸º {len(temp_forecast_list)}"
            )
        
        # ç”Ÿæˆæœªæ¥24å°æ—¶çš„æ—¶é—´ç‚¹
        time_points = [start_time + timedelta(hours=i) for i in range(24)]
        
        # æ„å»ºé¢„æµ‹æ•°æ®
        prediction_data = []
        for i, dt in enumerate(time_points):
            hour = dt.hour
            day_of_week = dt.weekday()
            temperature = temp_forecast_list[i]
            price = self._get_price(hour)
            
            prediction_data.append({
                'Hour': hour,
                'DayOfWeek': day_of_week,
                'Temperature': temperature,
                'Price': price
            })
        
        # åˆ›å»ºDataFrame
        X_pred = pd.DataFrame(prediction_data)
        
        # è¿›è¡Œé¢„æµ‹
        try:
            predictions = self.model.predict(X_pred)
            print(f"   âœ“ é¢„æµ‹å®Œæˆ!")
        except Exception as e:
            raise Exception(f"é¢„æµ‹æ—¶å‡ºé”™: {str(e)}")
        
        # æ„å»ºç»“æœ
        results = []
        for i, (dt, pred_load) in enumerate(zip(time_points, predictions)):
            results.append({
                'datetime': dt,
                'predicted_load': float(pred_load),
                'temperature': temp_forecast_list[i],
                'price': prediction_data[i]['Price'],
                'hour': prediction_data[i]['Hour'],
                'day_of_week': prediction_data[i]['DayOfWeek']
            })
        
        # æ‰“å°ç»Ÿè®¡ä¿¡æ¯
        avg_load = np.mean(predictions)
        max_load = np.max(predictions)
        min_load = np.min(predictions)
        
        print(f"\n   ğŸ“Š é¢„æµ‹ç»Ÿè®¡:")
        print(f"      - å¹³å‡è´Ÿè½½: {avg_load:.2f} kW")
        print(f"      - æœ€å¤§è´Ÿè½½: {max_load:.2f} kW (æ—¶åˆ»: {time_points[np.argmax(predictions)].strftime('%H:%M')})")
        print(f"      - æœ€å°è´Ÿè½½: {min_load:.2f} kW (æ—¶åˆ»: {time_points[np.argmin(predictions)].strftime('%H:%M')})")
        
        return results
    
    def predict_single(
        self,
        hour: int,
        day_of_week: int,
        temperature: float,
        price: float = None
    ) -> float:
        """
        å•ç‚¹é¢„æµ‹
        
        Args:
            hour: å°æ—¶ (0-23)
            day_of_week: æ˜ŸæœŸå‡  (0-6)
            temperature: æ¸©åº¦ (Â°C)
            price: ç”µä»·ï¼Œå¦‚æœä¸ºNoneåˆ™è‡ªåŠ¨æ ¹æ®hourè®¡ç®—
            
        Returns:
            é¢„æµ‹è´Ÿè½½ (kW)
        """
        if self.model is None:
            raise ValueError("æ¨¡å‹æœªåŠ è½½ï¼Œè¯·å…ˆè°ƒç”¨ load_model() æˆ– train_model()")
        
        if price is None:
            price = self._get_price(hour)
        
        X = pd.DataFrame([{
            'Hour': hour,
            'DayOfWeek': day_of_week,
            'Temperature': temperature,
            'Price': price
        }])
        
        prediction = self.model.predict(X)[0]
        return float(prediction)


def main():
    """
    ä¸»å‡½æ•° - æµ‹è¯•ä»£ç 
    """
    print("\n" + "ğŸ¯ " + "="*76)
    print("èƒ½æºè´Ÿè½½é¢„æµ‹ç³»ç»Ÿ - æµ‹è¯•è„šæœ¬")
    print("="*78 + "\n")
    
    # 1. å®ä¾‹åŒ–é¢„æµ‹å™¨
    print("ã€æ­¥éª¤ 1ã€‘å®ä¾‹åŒ– EnergyPredictor")
    print("-" * 80)
    predictor = EnergyPredictor()
    
    # 2. è®­ç»ƒæ¨¡å‹
    print("\nã€æ­¥éª¤ 2ã€‘è®­ç»ƒæ¨¡å‹")
    print("-" * 80)
    metrics = predictor.train_model(n_estimators=100)
    
    # 3. æµ‹è¯•åŠ è½½æ¨¡å‹
    print("\nã€æ­¥éª¤ 3ã€‘æµ‹è¯•åŠ è½½æ¨¡å‹")
    print("-" * 80)
    predictor_new = EnergyPredictor()
    predictor_new.load_model()
    
    # 4. é¢„æµ‹æœªæ¥24å°æ—¶
    print("\nã€æ­¥éª¤ 4ã€‘é¢„æµ‹æœªæ¥24å°æ—¶è´Ÿè½½")
    print("-" * 80)
    
    # ä½¿ç”¨æ˜å¤©çš„æ—¥æœŸ
    tomorrow = datetime.now().replace(hour=0, minute=0, second=0, microsecond=0) + timedelta(days=1)
    
    # æ¨¡æ‹Ÿæ¸©åº¦é¢„æµ‹ï¼ˆå¤å­£æ¸©åº¦æ¨¡å¼ï¼‰
    temp_forecast = [
        24.0, 23.5, 23.0, 22.8, 22.5, 23.0,  # 00:00-05:00 (å¤œé—´é™æ¸©)
        24.0, 25.0, 26.5, 28.0, 29.5, 30.5,  # 06:00-11:00 (å‡æ¸©)
        31.0, 31.5, 31.8, 31.5, 31.0, 30.0,  # 12:00-17:00 (é«˜æ¸©)
        28.5, 27.0, 26.0, 25.5, 25.0, 24.5   # 18:00-23:00 (é™æ¸©)
    ]
    
    predictions = predictor_new.predict_next_24h(
        start_time=tomorrow,
        temp_forecast_list=temp_forecast
    )
    
    # 5. æ˜¾ç¤ºé¢„æµ‹ç»“æœ
    print("\nã€æ­¥éª¤ 5ã€‘é¢„æµ‹ç»“æœå±•ç¤º")
    print("-" * 80)
    print(f"\né¢„æµ‹æ—¥æœŸ: {tomorrow.strftime('%Y-%m-%d')}\n")
    print(f"{'æ—¶é—´':<12} {'é¢„æµ‹è´Ÿè½½':<12} {'æ¸©åº¦':<10} {'ç”µä»·':<10} {'æ—¶æ®µ':<10}")
    print("-" * 80)
    
    for pred in predictions[:12]:  # åªæ˜¾ç¤ºå‰12å°æ—¶
        dt = pred['datetime']
        load = pred['predicted_load']
        temp = pred['temperature']
        price = pred['price']
        
        # åˆ¤æ–­æ—¶æ®µ
        if price == 0.3:
            period = "è°·æ—¶"
        elif price == 0.6:
            period = "å¹³æ—¶"
        else:
            period = "å³°æ—¶"
        
        print(f"{dt.strftime('%H:%M'):<12} {load:>8.2f} kW  {temp:>6.1f}Â°C  {price:>6.2f}å…ƒ  {period:<10}")
    
    print("... (å12å°æ—¶çœç•¥)")
    
    # 6. å•ç‚¹é¢„æµ‹æµ‹è¯•
    print("\nã€æ­¥éª¤ 6ã€‘å•ç‚¹é¢„æµ‹æµ‹è¯•")
    print("-" * 80)
    
    test_cases = [
        (0, 1, 24.0, "å‘¨ä¸€å‡Œæ™¨0ç‚¹ï¼Œ24Â°C"),
        (12, 1, 30.0, "å‘¨ä¸€ä¸­åˆ12ç‚¹ï¼Œ30Â°C"),
        (20, 1, 28.0, "å‘¨ä¸€æ™šä¸Š8ç‚¹ï¼Œ28Â°C"),
    ]
    
    for hour, dow, temp, desc in test_cases:
        pred = predictor_new.predict_single(hour, dow, temp)
        print(f"   {desc}: {pred:.2f} kW")
    
    # 7. æ€»ç»“
    print("\n" + "="*80)
    print("âœ… æµ‹è¯•å®Œæˆ!")
    print("="*80)
    print(f"\næ¨¡å‹æ€§èƒ½:")
    print(f"   - æµ‹è¯•é›† MAE:  {metrics['test_mae']:.2f} kW")
    print(f"   - æµ‹è¯•é›† RMSE: {metrics['test_rmse']:.2f} kW")
    print(f"\næ¨¡å‹å·²ä¿å­˜åˆ°: {predictor.model_path}")
    print(f"å¯ä»¥é€šè¿‡ load_model() åŠ è½½ä½¿ç”¨\n")


if __name__ == "__main__":
    main()
