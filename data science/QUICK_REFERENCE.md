# å¿«é€Ÿå‚è€ƒå¡ - å¢å¼ºæ•°æ®åˆ†æåŠŸèƒ½

## ğŸš€ å¿«é€Ÿå¼€å§‹

### å®‰è£…ä¾èµ–

```bash
cd /Users/achilles/Documents/code/data\ science
source venv/bin/activate
pip install scipy==1.11.4
```

### è¿è¡Œæµ‹è¯•

```bash
python back/services/test_analysis_enhanced.py
```

---

## ğŸ“¦ ä¸‰ä¸ªæ ¸å¿ƒæ–¹æ³•

### 1ï¸âƒ£ è´¨é‡æ£€æŸ¥ (Week 03 & 13)

```python
from back.services.analysis_service import AnalysisService
import pandas as pd

df = pd.read_csv('data.csv')
result = AnalysisService.perform_quality_check(df)

# è¾“å‡º
result['quality_score']           # 0-100 åˆ†
result['high_risk_columns']       # ç¼ºå¤±ç‡>5%çš„åˆ—
result['outlier_detection']       # å¼‚å¸¸å€¼è¯¦æƒ…
result['recommendations']         # æ”¹è¿›å»ºè®®
```

**è¿”å›çš„å…³é”®å­—æ®µ**:

- `quality_score`: è´¨é‡åˆ†æ•°
- `missing_analysis`: ç¼ºå¤±å€¼è¯¦æƒ…
- `outlier_detection`: å¼‚å¸¸å€¼ï¼ˆIQRæ–¹æ³•ï¼‰
- `duplicate_check`: é‡å¤è¡Œç»Ÿè®¡
- `data_summary`: æŒ‰ç±»å‹çš„æ•°æ®æ‘˜è¦

---

### 2ï¸âƒ£ ç›¸å…³æ€§åˆ†æ (Week 05)

```python
result = AnalysisService.calculate_correlations(df)

# è¾“å‡º
result['correlations']            # æ‰€æœ‰å˜é‡å¯¹çš„ç›¸å…³æ€§
result['high_correlations']       # |r|>0.7 çš„å˜é‡å¯¹
result['pearson_matrix']          # Pearson çŸ©é˜µ
result['spearman_matrix']         # Spearman çŸ©é˜µ
result['suggestions']             # å¤šé‡å…±çº¿æ€§å»ºè®®
```

**è¿”å›çš„å…³é”®å­—æ®µ**:

- `correlations`: è¯¦ç»†ç›¸å…³æ€§åˆ—è¡¨ï¼ˆå« p-valueï¼‰
- `high_correlations`: é«˜ç›¸å…³å˜é‡å¯¹
- `pearson_matrix`: å®Œæ•´ Pearson çŸ©é˜µ
- `spearman_matrix`: å®Œæ•´ Spearman çŸ©é˜µ

---

### 3ï¸âƒ£ ç»Ÿè®¡æ£€éªŒ (Week 04)

```python
result = AnalysisService.perform_statistical_tests(df)

# è¾“å‡º
result['normality_tests']         # æ¯åˆ—çš„æ­£æ€æ€§æ£€éªŒ
result['non_normal_columns']      # éæ­£æ€åˆ†å¸ƒåˆ—
result['summary']                 # æ±‡æ€»ç»Ÿè®¡
result['suggestions']             # è½¬æ¢å»ºè®®
```

**è¿”å›çš„å…³é”®å­—æ®µ**:

- `normality_tests`: æ¯åˆ—çš„ Shapiro-Wilk æˆ– D'Agostino-Pearson æ£€éªŒ
- `non_normal_columns`: éæ­£æ€åˆ—ååˆ—è¡¨
- `suggestions`: æ•°æ®è½¬æ¢å’Œæ–¹æ³•é€‰æ‹©å»ºè®®

---

## ğŸ”¥ ä¸€é”®ç»¼åˆåˆ†æ

```python
# æ¨èï¼šä¸€æ¬¡æ€§æ‰§è¡Œæ‰€æœ‰åˆ†æ
quality = AnalysisService.perform_quality_check(df)
corr = AnalysisService.calculate_correlations(df)
stats = AnalysisService.perform_statistical_tests(df)

print(f"è´¨é‡: {quality['quality_score']}/100")
print(f"é«˜ç›¸å…³: {len(corr['high_correlations'])} å¯¹")
print(f"éæ­£æ€: {len(stats['non_normal_columns'])} åˆ—")
```

---

## ğŸ¯ å®é™…åº”ç”¨åœºæ™¯

### åœºæ™¯1: æ•°æ®æ¥æ”¶è´¨é‡æ£€æŸ¥

```python
# æ–°æ•°æ®åˆ°è¾¾ï¼Œç«‹å³æ£€æŸ¥è´¨é‡
quality = AnalysisService.perform_quality_check(df)

if quality['quality_score'] < 70:
    print("âŒ æ•°æ®è´¨é‡ä¸åˆæ ¼")
    print(quality['recommendations'])
    # æ‹’ç»æ•°æ®æˆ–è§¦å‘æ¸…æ´—æµç¨‹
else:
    print("âœ… æ•°æ®è´¨é‡åˆæ ¼ï¼Œç»§ç»­å¤„ç†")
```

### åœºæ™¯2: å»ºæ¨¡å‰é¢„æ£€æŸ¥

```python
# å»ºæ¨¡å‰æ£€æŸ¥å¤šé‡å…±çº¿æ€§
corr = AnalysisService.calculate_correlations(df)

if corr['high_correlations']:
    print("âš ï¸ è­¦å‘Šï¼šå‘ç°å¤šé‡å…±çº¿æ€§")
    for hc in corr['high_correlations']:
        print(f"  {hc['variables'][0]} â†”ï¸ {hc['variables'][1]}: r={hc['correlation']}")
```

### åœºæ™¯3: é€‰æ‹©åˆé€‚çš„ç»Ÿè®¡æ–¹æ³•

```python
# ç¡®å®šæ˜¯å¦ä½¿ç”¨å‚æ•°æ£€éªŒ
stats = AnalysisService.perform_statistical_tests(df)

if stats['non_normal_columns']:
    print("ğŸ“Š å»ºè®®ä½¿ç”¨éå‚æ•°æ–¹æ³•")
    print(f"éæ­£æ€åˆ—: {stats['non_normal_columns']}")
else:
    print("ğŸ“Š å¯ä»¥ä½¿ç”¨å‚æ•°æ–¹æ³• (t-test, Pearson)")
```

---

## ğŸ“Š è¿”å›ç»“æœé€ŸæŸ¥

### Quality Check å…³é”®æŒ‡æ ‡

```json
{
  "quality_score": 85.5,           // 0-100
  "high_risk_columns": ["col1"],   // ç¼ºå¤±ç‡>5%
  "quality_metrics": {
    "total_missing": 50,           // æ€»ç¼ºå¤±æ•°
    "missing_rate": 5.0,           // ç¼ºå¤±ç‡%
    "total_outliers": 15,          // å¼‚å¸¸å€¼æ•°
    "duplicate_rows": 3            // é‡å¤è¡Œæ•°
  }
}
```

### Correlation å…³é”®æŒ‡æ ‡

```json
{
  "correlations": [
    {
      "variable_x": "age",
      "variable_y": "income",
      "pearson": {
        "correlation": 0.7523,
        "p_value": 0.000012,
        "significant": true          // p<0.05
      }
    }
  ],
  "high_correlations": [...]         // |r|>0.7
}
```

### Statistical Test å…³é”®æŒ‡æ ‡

```json
{
  "normality_tests": {
    "age": {
      "test_name": "Shapiro-Wilk",
      "p_value": 0.234567,
      "is_normal": true,             // p>=0.05
      "skewness": 0.15,
      "kurtosis": -0.5
    }
  },
  "non_normal_columns": ["income"]
}
```

---

## âš¡ æ€§èƒ½æç¤º

| æ•°æ®è§„æ¨¡ | å»ºè®® |
|---------|-----|
| < 1,000 è¡Œ | ç›´æ¥ä½¿ç”¨æ‰€æœ‰æ–¹æ³• |
| 1,000 - 10,000 | æ­£å¸¸ä½¿ç”¨ |
| 10,000 - 100,000 | è€ƒè™‘é‡‡æ ·æˆ–åˆ†æ‰¹ |
| > 100,000 | ä½¿ç”¨é‡‡æ ·ï¼ˆä¸å½±å“ IQR å’Œç›¸å…³æ€§è®¡ç®—ï¼‰ |

---

## ğŸ” åˆ¤æ–­æ ‡å‡†é€ŸæŸ¥

### è´¨é‡åˆ†æ•°åˆ¤æ–­

- **90-100**: ä¼˜ç§€ âœ…
- **70-89**: è‰¯å¥½ âš ï¸
- **50-69**: éœ€è¦æ¸…æ´— âš ï¸âš ï¸
- **< 50**: ä¸åˆæ ¼ âŒ

### ç›¸å…³æ€§å¼ºåº¦

- **|r| > 0.7**: å¼ºç›¸å…³ âš ï¸ æ³¨æ„å¤šé‡å…±çº¿æ€§
- **0.4 < |r| < 0.7**: ä¸­ç­‰ç›¸å…³
- **|r| < 0.4**: å¼±ç›¸å…³ âœ…

### ç¼ºå¤±å€¼é£é™©

- **> 5%**: é«˜é£é™© âŒ éœ€è¦å¤„ç†
- **1-5%**: ä¸­ç­‰é£é™© âš ï¸
- **< 1%**: ä½é£é™© âœ…

---

## ğŸš¨ å¸¸è§é”™è¯¯å¤„ç†

### é”™è¯¯1: æ ·æœ¬é‡ä¸è¶³

```python
# æ£€æŸ¥æ ·æœ¬é‡
if len(df) < 3:
    print("âŒ æ ·æœ¬é‡ä¸è¶³ï¼Œè‡³å°‘éœ€è¦3ä¸ªè§‚æµ‹å€¼")
```

### é”™è¯¯2: æ— æ•°å€¼åˆ—

```python
result = AnalysisService.calculate_correlations(df)
if not result['success']:
    print(f"âŒ {result['message']}")
    # "éœ€è¦è‡³å°‘2ä¸ªæ•°å€¼åˆ—æ‰èƒ½è®¡ç®—ç›¸å…³æ€§"
```

### é”™è¯¯3: å…¨æ˜¯NaN

```python
# æ–¹æ³•å†…éƒ¨å·²å¤„ç†ï¼Œä¼šè·³è¿‡å…¨NaNåˆ—
# æ£€æŸ¥è­¦å‘Šä¿¡æ¯
if 'error' in result['outlier_detection']['col_name']:
    print(f"âš ï¸ åˆ—å¤„ç†è­¦å‘Š: {result['outlier_detection']['col_name']['error']}")
```

---

## ğŸ“š å®Œæ•´æ–‡æ¡£é“¾æ¥

- è¯¦ç»†åŠŸèƒ½è¯´æ˜: `docs/ENHANCED_ANALYSIS_GUIDE.md`
- API é›†æˆç¤ºä¾‹: `docs/API_INTEGRATION_EXAMPLE.md`
- å®ç°æ€»ç»“: `IMPLEMENTATION_SUMMARY.md`
- æµ‹è¯•ä»£ç : `back/services/test_analysis_enhanced.py`

---

## ğŸ’¡ æœ€ä½³å®è·µ

1. âœ… **å…ˆè´¨é‡æ£€æŸ¥ï¼Œå†åˆ†æ**: ç¡®ä¿æ•°æ®è´¨é‡åˆæ ¼
2. âœ… **æ£€æŸ¥åˆ†å¸ƒï¼Œé€‰æ–¹æ³•**: æ ¹æ®æ­£æ€æ€§é€‰æ‹©å‚æ•°/éå‚æ•°æ–¹æ³•
3. âœ… **æ³¨æ„å¤šé‡å…±çº¿æ€§**: å»ºæ¨¡å‰æ£€æŸ¥é«˜ç›¸å…³å˜é‡
4. âœ… **é˜…è¯»å»ºè®®**: æ¯ä¸ªæ–¹æ³•éƒ½è¿”å› `suggestions` å­—æ®µ
5. âœ… **é”™è¯¯å¤„ç†**: å§‹ç»ˆæ£€æŸ¥ `result['success']`

---

## ğŸ“ è¯¾ç¨‹å¯¹åº”å…³ç³»

| æ–¹æ³• | è¯¾ç¨‹ | æ ¸å¿ƒæ¦‚å¿µ |
|-----|-----|---------|
| `perform_quality_check` | Week 03, 13 | Garbage in, garbage out |
| `calculate_correlations` | Week 05 | Correlation reveals association |
| `perform_statistical_tests` | Week 04 | Implementation Tips |

---

## âœ¨ è®°ä½è¿™äº›

```python
# ä¸‰ä¸ªæ–¹æ³•ï¼Œä¸€ä¸ªç›®æ ‡ï¼šè®©æ•°æ®åˆ†ææ›´ç§‘å­¦
quality = AnalysisService.perform_quality_check(df)      # è´¨é‡è¯„ä¼°
corr = AnalysisService.calculate_correlations(df)        # å…³ç³»åˆ†æ
stats = AnalysisService.perform_statistical_tests(df)    # åˆ†å¸ƒæ£€éªŒ

# ä¸‰ä¸ªé—®é¢˜ï¼Œä¸€ä¸ªæµç¨‹ï¼š
# 1. æ•°æ®è´¨é‡å¦‚ä½•ï¼Ÿ â†’ quality_score
# 2. å˜é‡ç›¸å…³å—ï¼Ÿ   â†’ high_correlations
# 3. åˆ†å¸ƒæ­£æ€å—ï¼Ÿ   â†’ non_normal_columns
```

---

**ç‰ˆæœ¬**: v1.0.0  
**çŠ¶æ€**: âœ… ç”Ÿäº§å°±ç»ª  
**æµ‹è¯•**: âœ… å·²é€šè¿‡
